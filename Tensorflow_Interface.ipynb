{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Tequila Tutorial\n",
    "\n",
    "In this tutorial we will learn how to transform a Tequila `Objective` into a `Tensorflow Layer object`, and will optimize such an objective using Tensorflow. In particular, we are going to train a Quantum Autoencoder on the $\\text{H}_{2}$, sto-3g, UCC-SD ansatz. We will consider, as input data, the angles of the UCC-SD state prep circuit, calculated at different bond lengths, and as internal weights to the model, the angles of rotation gates within the autoencoder circuit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tequila as tq\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.optimizers as optims\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Generate the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating a number of molecule objects, each representing $\\text{H}_{2}$ at different bond lengths. \n",
    "Subsequently, we extract the parameter value (there is only one) of the UCCSD ansatz, for preparing that state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_lengths=np.linspace(.3, 1.6, 20) # our bond length, in angstrom.\n",
    "amp_arrays = []\n",
    "state_preps = []\n",
    "for i in bond_lengths:\n",
    "    # the line below initializes a tequila molecule object for H2 at a specific bond length.\n",
    "    # see the quantum chemistry tutorial for more details.\n",
    "    molecule = tq.chemistry.Molecule(geometry = \"H 0.0 0.0 0.0\\n H 0.0 0.0 {}\".format(str(i)), basis_set=\"sto-3g\")\n",
    "    amplitude = molecule.compute_amplitudes(method='ccsd') # get the state prep amplitudes\n",
    "    amp_arrays.append(np.asarray([v for v in amplitude.make_parameter_dictionary().values()]))\n",
    "    state_preps.append(molecule.make_uccsd_ansatz(trotter_steps=1,initial_amplitudes=amplitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must create our data loader and subsequently the dataset from the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(amp_arrays):\n",
    "    i = 0\n",
    "    while i < len(amp_arrays):\n",
    "        yield amp_arrays[i]\n",
    "        i += 1\n",
    "\n",
    "my_data = tf.data.Dataset.from_generator(data_generator, args=[amp_arrays], output_types=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Create an Ansatz `Objective`.\n",
    "\n",
    "Our autoencoder ansatz must be a circuit that both constructs the hydrogen wavefunction, and then compresses it. Furthermore, the autoencoder cost function must be encoded into the objective. The cost function can be defined as a hamiltonian which projects all the non-latent, or 'trash' qubits, onto the all zero state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined state prep, encoder circuit:  \n",
      " circuit: \n",
      "X(target=(0,))\n",
      "X(target=(1,))\n",
      "FermionicEx(target=(0, 1, 2, 3), control=(), parameter=Objective with 0 unique expectation values\n",
      "variables = [(1, 0, 1, 0)]\n",
      "types     = [])\n",
      "FermionicEx(target=(0, 1, 2, 3), control=(), parameter=Objective with 0 unique expectation values\n",
      "variables = [(1, 0, 1, 0)]\n",
      "types     = [])\n",
      "Rx(target=(0,), parameter=a)\n",
      "Rx(target=(1,), parameter=b)\n",
      "X(target=(3,), control=(1,))\n",
      "X(target=(2,), control=(0,))\n",
      "X(target=(1,), control=(0,))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = tq.gates.Rx('a',0) +tq.gates.Rx('b',1) +tq.gates.CNOT(1,3) +tq.gates.CNOT(0,2)+tq.gates.CNOT(0,1)\n",
    "state_prep = state_preps[0] # every member of this list is the same object; it doesn't matter which we pick.\n",
    "combined = state_prep + encoder\n",
    "print('combined state prep, encoder circuit:  \\n', combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2 autoencoder:  Objective with 1 unique expectation values\n",
      "variables = [(1, 0, 1, 0), a, b]\n",
      "types     = not compiled\n"
     ]
    }
   ],
   "source": [
    "# we decide that the 3rd and 4th qubits will be trash qubits. The hamiltonian below projects onto zero.\n",
    "hamiltonian = tq.hamiltonian.paulis.Qm(2)*tq.hamiltonian.paulis.Qm(3)\n",
    "h2_encoder = tq.ExpectationValue(U=combined,H=hamiltonian)\n",
    "print('H2 autoencoder: ', h2_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Convert the Tequila `Objective` into a Tensorflow `Layer`.\n",
    "\n",
    "In order for Tensoflow to interact with Tequila objectives, we need to build wrappers which allow the classes of Tensorflow and tequila to work together. For user convenience, this can be done with the class `TFLayer`. \n",
    "This class takes an `Objective`, a dict of compilation args (optional), and a list of `Variable`s of the objective which should be treated as input (the data loaded into `my_data`), and will treat all the remaining variables as internal weights of the quantum neural network layer that the objective constitutes. If not specified in the compile_args dictionary, random values (between 0 and $2 \\pi$) will be used for the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_variable=h2_encoder.extract_variables()[0]\n",
    "inits={'a':1.5, 'b':1.5}\n",
    "compile_args={'backend':'qulacs', 'initial_values':inits} # dict. allowed keys: backend, samples, noise, device, initial_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tequila TFLayer. Represents: \n",
      "VectorObjective with 1 unique expectation values\n",
      "variables = [(1, 0, 1, 0), a, b]\n",
      "types     = not compiled \n",
      "Current Weights: [a, b]\n"
     ]
    }
   ],
   "source": [
    "my_tf_encoder = tq.ml.interface_tf.TFLayer(h2_encoder,compile_args,input_vars=[input_variable])\n",
    "print(my_tf_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Optimize using Tensorflow and plot the results.\n",
    "\n",
    "Once converted to a Tensorflow layer, Tequila `Objective`'s can be optimized with the inbuilt tools of Tensorflow. Do note that `TFLayer` objects cannot be optimized with the tequila optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = optims.Adam(lr=0.01)\n",
    "\n",
    "var_list_fn = lambda: my_tf_encoder.get_params_variable()  # We just want to train the parameters\n",
    "\n",
    "loss_fn = lambda: tf.reduce_sum(my_tf_encoder())\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 1 ***\n",
      "0.28661953875879514\n",
      "0.28130241917954657\n",
      "0.2760331406621527\n",
      "0.27081308558648287\n",
      "0.26564370891707356\n",
      "0.26052634904435007\n",
      "0.25546235029919073\n",
      "0.25045299959169653\n",
      "0.24549958476315759\n",
      "0.24060327404798776\n",
      "Batched Average Loss:  0.26329564508504333 \n",
      "\n",
      "*** Epoch 2 ***\n",
      "0.23576523425880314\n",
      "0.23098651283706303\n",
      "0.2262682104855237\n",
      "0.2216113067440262\n",
      "0.217016662920977\n",
      "0.21248518952572568\n",
      "0.2080176235025597\n",
      "0.20361474878530036\n",
      "0.19927717870176262\n",
      "0.19500546718427048\n",
      "Batched Average Loss:  0.2150048134946012 \n",
      "\n",
      "*** Epoch 3 ***\n",
      "0.1908001609162413\n",
      "0.18666164369491722\n",
      "0.18259034496963128\n",
      "0.17858653523365378\n",
      "0.17465043141595218\n",
      "0.1707821492622906\n",
      "0.16698185110090685\n",
      "0.16324950427720847\n",
      "0.15958507816839568\n",
      "0.15598845013005283\n",
      "Batched Average Loss:  0.172987614916925 \n",
      "\n",
      "*** Epoch 4 ***\n",
      "0.15245945515901937\n",
      "0.14899784227520327\n",
      "0.145603322983753\n",
      "0.14227557249498216\n",
      "0.1390141879840553\n",
      "0.13581869285013062\n",
      "0.13268858272546924\n",
      "0.1296233266893675\n",
      "0.12662232786985483\n",
      "0.12368492756903729\n",
      "Batched Average Loss:  0.13767882386008726 \n",
      "\n",
      "*** Epoch 5 ***\n",
      "0.12081048824016816\n",
      "0.11799831397226276\n",
      "0.11524761615184534\n",
      "0.11255767123088357\n",
      "0.10992763009771142\n",
      "0.10735671070251676\n",
      "0.10484404902648171\n",
      "0.10238877660191462\n",
      "0.09999002135550503\n",
      "0.09764687389650381\n",
      "Batched Average Loss:  0.10887681512757932 \n",
      "\n",
      "*** Epoch 6 ***\n",
      "0.09535842491838517\n",
      "0.09312373240753084\n",
      "0.09094185785365924\n",
      "0.0888118668474327\n",
      "0.08673279764690217\n",
      "0.08470369567406652\n",
      "0.08272358293168826\n",
      "0.08079155250033962\n",
      "0.07890658361347266\n",
      "0.07706772914669857\n",
      "Batched Average Loss:  0.08591618235401757 \n",
      "\n",
      "*** Epoch 7 ***\n",
      "0.07527405287277351\n",
      "0.0735246297326333\n",
      "0.07181848948577564\n",
      "0.07015467700767859\n",
      "0.06853230724289983\n",
      "0.06695039895132583\n",
      "0.06540804278232835\n",
      "0.06390439708767026\n",
      "0.06243852915441622\n",
      "0.061009524819943164\n",
      "Batched Average Loss:  0.06790150491374447 \n",
      "\n",
      "*** Epoch 8 ***\n",
      "0.05961653833793669\n",
      "0.058258739136560864\n",
      "0.056935263272259534\n",
      "0.055645264829616944\n",
      "0.05438791572651745\n",
      "0.05316245181896506\n",
      "0.05196807795675032\n",
      "0.050803971351269905\n",
      "0.049669417440772703\n",
      "0.04856362861258533\n",
      "Batched Average Loss:  0.053901126848323475 \n",
      "\n",
      "*** Epoch 9 ***\n",
      "0.047485922261262484\n",
      "0.04643554495986679\n",
      "0.04541180353177707\n",
      "0.04441402057671738\n",
      "0.04344149385197471\n",
      "0.04249361833619544\n",
      "0.041569684079517014\n",
      "0.04066911632471644\n",
      "0.039791276382748667\n",
      "0.038935579458296385\n",
      "Batched Average Loss:  0.043064805976307234 \n",
      "\n",
      "*** Epoch 10 ***\n",
      "0.03810141774012507\n",
      "0.03728823556279885\n",
      "0.036495454758298906\n",
      "0.03572254760291785\n",
      "0.034968964353416135\n",
      "0.03423420405678544\n",
      "0.033517777957601275\n",
      "0.03281917598212178\n",
      "0.0321379016922084\n",
      "0.03147350427574368\n",
      "Batched Average Loss:  0.03467591839820174 \n",
      "\n",
      "*** Epoch 11 ***\n",
      "0.03082554405027811\n",
      "0.03019356083408313\n",
      "0.0295771069037033\n",
      "0.028975807696827977\n",
      "0.028389206817339335\n",
      "0.02781695015348272\n",
      "0.027258633094241203\n",
      "0.026713862131601193\n",
      "0.026182282991066924\n",
      "0.02566355035231102\n",
      "Batched Average Loss:  0.028159650502493493 \n",
      "\n",
      "*** Epoch 12 ***\n",
      "0.025157327645311325\n",
      "0.024663259603140086\n",
      "0.024181000814735953\n",
      "0.023710268467023954\n",
      "0.023250733908486365\n",
      "0.022802103437621457\n",
      "0.022364090874141707\n",
      "0.021936392293591553\n",
      "0.021518761787286414\n",
      "0.021110910244246828\n",
      "Batched Average Loss:  0.023069484907558564 \n",
      "\n",
      "*** Epoch 13 ***\n",
      "0.020712580774058936\n",
      "0.020323523111111408\n",
      "0.019943470001769104\n",
      "0.019572208019571324\n",
      "0.01920950579925007\n",
      "0.018855115437042658\n",
      "0.018508840537882487\n",
      "0.018170445317528316\n",
      "0.0178397440228851\n",
      "0.017516533785307264\n",
      "Batched Average Loss:  0.01906519668064067 \n",
      "\n",
      "*** Epoch 14 ***\n",
      "0.017200595908802074\n",
      "0.01689175960945566\n",
      "0.01658983745631326\n",
      "0.01629464690955007\n",
      "0.01600601019550238\n",
      "0.015723773985861778\n",
      "0.01544776892901134\n",
      "0.015177830106291923\n",
      "0.014913796917430777\n",
      "0.014655512968699824\n",
      "Batched Average Loss:  0.01589015329869191 \n",
      "\n",
      "*** Epoch 15 ***\n",
      "0.014402844560828854\n",
      "0.014155642700932947\n",
      "0.013913780447969176\n",
      "0.013677115860282085\n",
      "0.013445510725248688\n",
      "0.013218847949545642\n",
      "0.012996995854020033\n",
      "0.012779843291792686\n",
      "0.012567264805147693\n",
      "0.012359138238582701\n",
      "Batched Average Loss:  0.013351698443435051 \n",
      "\n",
      "*** Epoch 16 ***\n",
      "0.012155377582801052\n",
      "0.011955849586968492\n",
      "0.011760473088243018\n",
      "0.01156913661670858\n",
      "0.011381731642209653\n",
      "0.011198168017810484\n",
      "0.011018357661694095\n",
      "0.010842214510853765\n",
      "0.010669639485495513\n",
      "0.010500550940149234\n",
      "Batched Average Loss:  0.01130514991329339 \n",
      "\n",
      "*** Epoch 17 ***\n",
      "0.010334869098746674\n",
      "0.010172501529495781\n",
      "0.010013372561075068\n",
      "0.00985740825235662\n",
      "0.009704536353147497\n",
      "0.009554686265747847\n",
      "0.009407775319596356\n",
      "0.009263736565490288\n",
      "0.009122517968653154\n",
      "0.008984041920479857\n",
      "Batched Average Loss:  0.009641544583478915 \n",
      "\n",
      "*** Epoch 18 ***\n",
      "0.00884824595906819\n",
      "0.008715056097439167\n",
      "0.00858442592459252\n",
      "0.008456297151709369\n",
      "0.008330612819697603\n",
      "0.008207317268573933\n",
      "0.008086343840943755\n",
      "0.007967651914169593\n",
      "0.00785118954284536\n",
      "0.007736905964946139\n",
      "Batched Average Loss:  0.008278404648398564 \n",
      "\n",
      "*** Epoch 19 ***\n",
      "0.007624751574454858\n",
      "0.007514677894602251\n",
      "0.007406637551711559\n",
      "0.007300584249634867\n",
      "0.0071964727447723364\n",
      "0.007094269976016143\n",
      "0.006993921347938747\n",
      "0.00689539556127039\n",
      "0.006798651013529389\n",
      "0.006703647047441974\n",
      "Batched Average Loss:  0.0071529008961372514 \n",
      "\n",
      "*** Epoch 20 ***\n",
      "0.006610343928938667\n",
      "0.006518702825663691\n",
      "0.006428696168771175\n",
      "0.006340286554282454\n",
      "0.006253437427007763\n",
      "0.006168113060746494\n",
      "0.006084288513484637\n",
      "0.006001919487719443\n",
      "0.0059209921913515595\n",
      "0.005841463770813071\n",
      "Batched Average Loss:  0.006216824392877895 \n",
      "\n",
      "*** Epoch 21 ***\n",
      "0.005763311679453764\n",
      "0.005686504229401312\n",
      "0.005611010450309428\n",
      "0.005536809384193847\n",
      "0.005463871176768165\n",
      "0.0053921666493088605\n",
      "0.005321667282877002\n",
      "0.0052523631225546985\n",
      "0.005184217537946956\n",
      "0.005117212444083391\n",
      "Batched Average Loss:  0.005432913395689742 \n",
      "\n",
      "*** Epoch 22 ***\n",
      "0.005051321323364055\n",
      "0.004986518257250133\n",
      "0.004922786457677519\n",
      "0.004860109389225764\n",
      "0.004798462379021484\n",
      "0.0047378213113211665\n",
      "0.004678170847204788\n",
      "0.004619487719399601\n",
      "0.004561749185436836\n",
      "0.004504941023907444\n",
      "Batched Average Loss:  0.004772136789380879 \n",
      "\n",
      "*** Epoch 23 ***\n",
      "0.00444904922258435\n",
      "0.0043940521122535214\n",
      "0.004339928512061442\n",
      "0.004286665440610515\n",
      "0.004234250105238813\n",
      "0.004182662315036584\n",
      "0.0041318823336788935\n",
      "0.004081898319272831\n",
      "0.004032698599898299\n",
      "0.003984264352260375\n",
      "Batched Average Loss:  0.004211735131289562 \n",
      "\n",
      "*** Epoch 24 ***\n",
      "0.003936584431393442\n",
      "0.00388964066013886\n",
      "0.0038434152698492152\n",
      "0.0037979050242993584\n",
      "0.0037530925760657086\n",
      "0.0037089609673413015\n",
      "0.003665500505990793\n",
      "0.003622694809318344\n",
      "0.003580534629641252\n",
      "0.00353901084740893\n",
      "Batched Average Loss:  0.0037337339721447206 \n",
      "\n",
      "*** Epoch 25 ***\n",
      "0.0034981078169147306\n",
      "0.0034578168395614783\n",
      "0.0034181293365347365\n",
      "0.003379030361700064\n",
      "0.0033405117349165903\n",
      "0.003302559010354811\n",
      "0.003265164389814501\n",
      "0.0032283201807574713\n",
      "0.0031920125751316863\n",
      "0.00315623424214595\n",
      "Batched Average Loss:  0.003323788648783202 \n",
      "\n",
      "*** Epoch 26 ***\n",
      "0.0031209718316588253\n",
      "0.0030862183594156933\n",
      "0.0030519669341087796\n",
      "0.003018210756356887\n",
      "0.002984937197011872\n",
      "0.002952139781262769\n",
      "0.0029198062945621217\n",
      "0.002887930572980757\n",
      "0.0028565065331841166\n",
      "0.002825522485208176\n",
      "Batched Average Loss:  0.002970421074575 \n",
      "\n",
      "*** Epoch 27 ***\n",
      "0.002794978281258853\n",
      "0.002764862476811597\n",
      "0.0027351638817221247\n",
      "0.002705877062578521\n",
      "0.0026769966556102753\n",
      "0.0026485173659475114\n",
      "0.002620428587420065\n",
      "0.002592730624101258\n",
      "0.00256540778996997\n",
      "0.002538460558279304\n",
      "Batched Average Loss:  0.002664342328369948 \n",
      "\n",
      "*** Epoch 28 ***\n",
      "0.0025118788710289663\n",
      "0.0024856580670281625\n",
      "0.002459793543756472\n",
      "0.0024342756615557404\n",
      "0.0024091000500627846\n",
      "0.002384262393252068\n",
      "0.002359758428873704\n",
      "0.0023355790058113\n",
      "0.0023117200794969817\n",
      "0.0022881776551025856\n",
      "Batched Average Loss:  0.0023980203755968764 \n",
      "\n",
      "*** Epoch 29 ***\n",
      "0.002264947787030125\n",
      "0.002242021783091519\n",
      "0.0022194006614089934\n",
      "0.002197071171495063\n",
      "0.002175034457696845\n",
      "0.0021532869136025035\n",
      "0.0021318203566168537\n",
      "0.0021106313698504853\n",
      "0.002089716577502565\n",
      "0.0020690681249264653\n",
      "Batched Average Loss:  0.0021652999203221417 \n",
      "\n",
      "*** Epoch 30 ***\n",
      "0.002048682815968733\n",
      "0.0020285619463520366\n",
      "0.0020086934549116142\n",
      "0.0019890787445016045\n",
      "0.0019697147680873828\n",
      "0.0019505941879897903\n",
      "0.0019317141224066692\n",
      "0.0019130717232896943\n",
      "0.0018946641760122507\n",
      "0.0018764844940711012\n",
      "Batched Average Loss:  0.0019611260433590877 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print('*** Epoch {} ***'.format(epoch + 1))\n",
    "    batch = my_data.shuffle(20).take(10)\n",
    "    batch_loss = []\n",
    "    for point in batch:\n",
    "        pred = my_tf_encoder(point)\n",
    "        loss = loss_fn()\n",
    "        batch_loss.append(loss)\n",
    "        print(loss.numpy())\n",
    "\n",
    "        # Get the gradients and apply them\n",
    "        optim.minimize(loss_fn, var_list_fn)\n",
    "    bv = np.mean([l.numpy() for l in batch_loss])\n",
    "    loss_values.append(bv)\n",
    "    print('Batched Average Loss: ', bv, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final parameter values: \n",
      "OrderedDict([('a', 2.723287343978882), ('b', 2.723287343978882)])\n"
     ]
    }
   ],
   "source": [
    "print(\"Final parameter values: \")\n",
    "print(my_tf_encoder.get_params_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_values, label='loss per epoch')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch', fontsize=18)\n",
    "plt.ylabel('Autoencoder Loss', fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tequila",
   "language": "python",
   "name": "tequila"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
